In high energy physics, Scientists use various methods to detect and recognise a particle. Some methods include:

1. Cherenkov radiation
2. Calorimeter
3. Scintillation Counters
4. Time of-flight

Though these methods are highly accurate but by the natural instinct of particles, certain particles can go missing and unnoticed. Like it took us a long time to find Neutrino, the same goes for more ghost particles that we don’t know about yet. 

Stealing a glance from traditional thinking, if we put a glance towards modern thinking, Harvard’s research tells us “Acoustic methods can be used to detect Neutrinos”. High energy particles by nature do not produce sound waves as they move through vacuum within the particle accelerator and by its own it only creates electro-magnetic signatures and other markers. 

But, when particles are smashed/collided against a target(solid object) we can hear a faint sound though those sound waves can’t be heard by humans, sensitive equipment can pick them up and store them as audio readings. Afterwards, there’s a concept, where piezoelectric materials are used by particle accelerators and convert particle collision energy to electric signal and further amplified to create audible sound. All these opens-up the possibility of Artificial Intelligence being infused with particle recognition and detection.

<h3>What Berlin is?</h3>
Berlin is a project where Artificial Intelligence is used to detect exotic and unseen particles by their generated audio. (while they collide with a target)

<h3>How Berlin works?</h3>
At its heart, first, audio sound is collected from particle collision then denoising Algorithm removes any unwanted/Gaussian noise/white noise. After that, the audio file is converted into an audio spectrogram and logarithmic transformation is applied. This transformed audio spectrogram is then stored into a file.

A convolutional network, classifies the audio spectrogram into relevant classes. The Conv network is previously trained on labelled audio spectrogram photos dataset. Through fine-tuning the model always stays relevant and overcomes uncertainty.

<h3>What are the challenges with Berlin?</h3> 
Currently, there’s no adequate dataset to train Berlin on except for a few examples created by me. And these and other challenges are:

<ol>
<li)Absence of adequate dataset</li>
<li>Classifying unknown particles  with Conv network</li>
<li>A custom denoising Algorithm to remove noise from particle’s audio files</li>
<li>A depth physics study and research on how temperature, cross-sectional area, target structure and other factors can change sound waves.</li>
</ol>

<h3>Future plan</h3>
I am planning to resolve the challenges within Berlin. That might take a few months as I have to collaborate with a few individuals and labs to publish Berlin as a research paper. 

<h3>Author’s note</h3>
Recently, I became sick with Typhoid fever. And it had some noticeable and semi-permanent neurological effects on my motor skills and memory. I have recovered mostly with some tremors in my hands and sleepiness, which doctors said will take a few months to a year to fully recover. 

That’s why, I started a 24 hours challenge concept, where I take a favourite subject of my choice and think of an idea and infuse Artificial Intelligence to create something meaningful and Berlin is one of the first few projects to be made. Hahaha, more to come!
